{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a73638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_functions as my_func\n",
    "import numpy as np  \n",
    "import warnings\n",
    "import time\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385623c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function set_params()\n",
    "# chunk 1\n",
    "class Detector():\n",
    "    def __init__(self, method = 'loda'):\n",
    "        self.method = method\n",
    "        \n",
    "    def get_data(self, path):\n",
    "        \"\"\"\n",
    "        The imported csv/xlsx should have no missing values as well as no \n",
    "        empty rows or columns.\n",
    "        \"\"\"\n",
    "        path = path.replace('\\\\','/') # reverse slash, as the backslash is not acceptable in python\n",
    "        path = path.translate({ord(\"\\\"\"):None}) # removes \"\" from the beggining and the end of the path\n",
    "        if path[-4:]=='xlsx':                                                   \n",
    "            ds = pd.read_excel(path)\n",
    "        elif path[-3:]=='csv':\n",
    "            ds = pd.read_csv(path)\n",
    "        else:\n",
    "            raise Exception(\"Not acceptable type of file\\n\"\n",
    "                          \"Only .csv or .xlsx files can be inputted\")\n",
    "        return (ds)\n",
    "\n",
    "    def detect(self, ds, train_split = 0.5, con = 0.1, n = 3, threshold = 0.3 ):\n",
    "        method = self.method\n",
    "        train_split = float(train_split)\n",
    "        con = float(con)\n",
    "        n = int(n)\n",
    "        th = float(threshold)\n",
    "        if method != 'ngram' and method != 'AE' and method != 'IF' and method != 'loda':\n",
    "            raise Exception(\"The available methods are: 'loda', 'AE', 'IF', 'ngram'.\\n\"\n",
    "                           \"Please choose one of the available methods.\")\n",
    "        if method!='ngram':\n",
    "            if train_split > 1 or train_split < 0:\n",
    "                raise Exception(\"The training split parameters represents the percentage \\n\"\n",
    "                               \"of the dataset that is used for training. Therefore, allowed \\n\"\n",
    "                               \"values are between 0 and 1\")\n",
    "\n",
    "        if method == 'loda' or method == 'AE' or method == 'IF':\n",
    "            # Drop any attriibute that is not numerical\n",
    "            for col in ds.columns:\n",
    "                if type(ds[col][1])!=np.int64 and type(ds[col][1])!=np.float64:\n",
    "                    ds.drop(col,axis=1,inplace=True)\n",
    "        else:\n",
    "            # Drop any attribute that is not string\n",
    "            for col in ds.columns:\n",
    "                if type(ds[col][0]) != str:\n",
    "                    ds.drop(col,axis=1,inplace=True)\n",
    "        if method != 'ngram':\n",
    "            sample_size = int(train_split*len(ds))\n",
    "            indices = random.sample(range(0, len(ds)), sample_size)\n",
    "            sample = ds.iloc[indices]\n",
    "            \n",
    "        size = \"big\" if len(ds) > 10000 else \"small\"\n",
    "        config = my_func.read_config()\n",
    "        epochs = int(config[size]['epochs'])\n",
    "        activation_function = config[size]['activation_function']\n",
    "        batch_size = int(config[size]['batch_size'])\n",
    "        if config[size]['lay'] == 'long':\n",
    "            layers=[64,32,16,1,16,32,64]\n",
    "        if config[size]['lay'] == 'short':\n",
    "            layers=[32,16,1,16,32]\n",
    "        estimators=config[size]['estimators']\n",
    "        \n",
    "        if method == 'AE':\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            start=time.time()\n",
    "            ds_pred=my_func.autoencoder_detection(ds ,sample, layers=layers,epo=epochs,\n",
    "                                                  activation_function=activation_function,\n",
    "                                                  batch=batch_size,cont=con)\n",
    "\n",
    "            finish=time.time()\n",
    "            print('It took ', finish-start,' seconds')\n",
    "        elif method=='IF':\n",
    "            start=time.time()\n",
    "            ds_pred=my_func.IsolationForest_detection(ds, sample, estimators=estimators)\n",
    "            finish=time.time()\n",
    "            print('It took ', finish-start,' seconds')\n",
    "        elif method=='loda':\n",
    "            start=time.time()\n",
    "            ds_pred=my_func.loda_detection(ds, sample)\n",
    "            finish=time.time()\n",
    "            print('It took ', finish-start,' seconds')\n",
    "        elif method=='ngram' and att_ranking==0 :\n",
    "            start=time.time()\n",
    "            ds_pred=my_func.ngrams_detection(ds, n, th)\n",
    "            finish=time.time()\n",
    "            print('It took ', finish-start,' seconds')\n",
    "        return (ds_pred)\n",
    "\n",
    "\n",
    "class Ranker():\n",
    "    def __init__(self,  method='loda', att_ranking = 0, PageRank = 0, threshold = 0.1):\n",
    "        self.att_ranking = att_ranking\n",
    "        self.PageRank = PageRank\n",
    "        self.threshold = threshold\n",
    "        self.method= method\n",
    "    def rank(self, ds_pred, ds, function = 'mean'): \n",
    "        att_ranking = int(self.att_ranking)\n",
    "        ind = int(self.PageRank)\n",
    "        th = float(self.threshold)\n",
    "        method = self.method\n",
    "        if att_ranking == 0:                        # th is tuples in the top % interval score\n",
    "            # ranking by tuples\n",
    "            if method != 'ngram':\n",
    "                if ind == 0:\n",
    "                    final=my_func.count_anomalies(ds_pred,method)\n",
    "                    range_of_val=max(final['Ranking_count'])-min(final['Ranking_count'])\n",
    "                    limit=(1-th)*range_of_val+min(final['Ranking_count'])\n",
    "                    return [final[final['Ranking_count']>limit].index, len(final[final['Ranking_count']>limit].index)/len(ds) ]\n",
    "                elif ind==1:\n",
    "                    edges=my_func.get_edges(ds_pred,method)\n",
    "                    nodes=my_func.get_nodes(ds_pred,method)\n",
    "                    G=my_func.build_network(nodes,edges)\n",
    "                    final=my_func.pagerank_score(G,ds_pred)\n",
    "                    range_of_val=max(final['PageRank score'])-min(final['PageRank score'])\n",
    "                    limit=(1-th)*range_of_val+min(final['PageRank score'])\n",
    "                    return [final[final['PageRank score']>limit].index, len(final[final['PageRank score']>limit].index)/len(ds)]\n",
    "            else:\n",
    "                return (my_func.ngrams_ranking(ds_pred, th))\n",
    "        else:\n",
    "            # ranking by attribute\n",
    "            if method!='ngram':\n",
    "                return (my_func.dataframe_score(ds_pred,ds,method,func, th))\n",
    "            if method=='ngram':\n",
    "                score=my_func.ngram_score_att(ds,n,th)\n",
    "                norm=my_func.maximum_score_att(ds,n)\n",
    "                df=pd.DataFrame({'normalized_score':score/norm})\n",
    "                if function=='mean':\n",
    "                    score = np.mean(score/norm)\n",
    "                if function=='median':\n",
    "                    score = np.median(score/norm)\n",
    "\n",
    "                return [df[df.normalized_score>1-th].index, score]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
