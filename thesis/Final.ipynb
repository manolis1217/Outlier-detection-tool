{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a73638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_functions as my_func\n",
    "import numpy as np  \n",
    "import warnings\n",
    "import time\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385623c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # chunk 1\n",
    "    \"\"\"\n",
    "    The imported csv/xlsx should have no missing values as well as no \n",
    "    empty rows or columns.\n",
    "    \"\"\"\n",
    "    in_path= input('Import the path of the file to be tested on anomalies\\n')\n",
    "    path=in_path.replace('\\\\','/') # reverse slash, as the backslash is not acceptable in python\n",
    "    path=path.translate({ord(\"\\\"\"):None}) # removes \"\" from the beggining and the end of the path\n",
    "    if path[-4:]=='xlsx':                                                   \n",
    "        ds=pd.read_excel(path)\n",
    "    elif path[-3:]=='csv':\n",
    "        ds=pd.read_csv(path)\n",
    "    else:\n",
    "        raise Exception(\"Not acceptable type of file\\n\"\n",
    "                      \"Only .csv or .xlsx files can be inputted\")\n",
    "    \n",
    "    # chunk 1-2\n",
    "    size = input(\"Is the dataset extensive or small?\\n\"\n",
    "                \"Indication: <10000 is small, otherwise it is big\"\n",
    "                \"Enter size (small/big):\").lower()\n",
    "    if size!='small' and size!='big':\n",
    "        raise Exception(\"Not acceptable size variable.\")\n",
    "        \n",
    "    # importing hyper parameters\n",
    "    config = my_func.read_config()\n",
    "    epochs=int(config[size]['epochs'])\n",
    "    activation_function=config[size]['activation_function']\n",
    "    batch_size=int(config[size]['batch_size'])\n",
    "    if config[size]['lay']=='long':\n",
    "        layers=[64,32,16,1,16,32,64]\n",
    "    if config[size]['lay']=='short':\n",
    "        layers=[32,16,1,16,32]\n",
    "    estimators=config[size]['estimators']\n",
    "    \n",
    "    att_ranking = input('Do you want to rank the dataset by rows or by attribute?\\n'\n",
    "                     '0: Ranking by rows\\n'\n",
    "                     '1: Ranking by attributes\\n'\n",
    "                     'Enter the variable:\\n\\n')\n",
    "    att_ranking=int(att_ranking)\n",
    "    if att_ranking!=0 and att_ranking!=1:\n",
    "        raise Exception('Invalid input')\n",
    "    # chunk 2\n",
    "    \"\"\"\n",
    "    Import parameters for the program such as: \n",
    "    - method to be used for outlier detection\n",
    "    - percentage of dataset to be used as training\n",
    "    \"\"\"\n",
    "    method=input('Enter the desired method. \\n'\n",
    "                         \"available methods are: 'ngram', 'AE', 'IF', 'loda'\\n\"\n",
    "                         'Enter the parameter:')\n",
    "    if method!='ngram' and method!='AE' and method!='IF' and method!='loda':\n",
    "        raise Exception(\"The available methods are: 'loda', 'AE', 'IF', 'ngram'.\\n\"\n",
    "                       \"Please choose one of the available methods.\")\n",
    "    if method!='ngram':\n",
    "        train_split=float(input('Enter the training split of the dataset:'))\n",
    "\n",
    "    if method!='ngram':\n",
    "        if train_split>1 or train_split<0:\n",
    "            raise Exception(\"The training split parameters represents the percentage \\n\"\n",
    "                           \"of the dataset that is used for training. Therefore, allowed \\n\"\n",
    "                           \"values are between 0 and 1\")\n",
    "    # chunk 3       \n",
    "    if method=='loda' or method=='AE' or method=='IF':\n",
    "        # Drop any attriibute that is not numerical\n",
    "        for col in ds.columns:\n",
    "            if type(ds[col][1])!=np.int64 and type(ds[col][1])!=np.float64:\n",
    "                ds.drop(col,axis=1,inplace=True)\n",
    "\n",
    "    else:\n",
    "        # Drop any attribute that is not string\n",
    "        for col in ds.columns:\n",
    "            if type(ds[col][0])!=str:\n",
    "                ds.drop(col,axis=1,inplace=True)\n",
    "\n",
    "    # chunk 4\n",
    "    if method!='ngram':\n",
    "        sample_size=int(train_split*len(ds))\n",
    "        indices=random.sample(range(0, len(ds)), sample_size)\n",
    "        sample=ds.iloc[indices]\n",
    "\n",
    "    # chunk 5\n",
    "    if method=='AE':\n",
    "        print('Autoencoder method initiated for outlier detection')\n",
    "        con=input('Contamination parameter needs to be established for the Autoencoder\\n'\n",
    "                             'Enter the parameter:')\n",
    "        con=float(con)\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        start=time.time()\n",
    "        ds_pred=my_func.autoencoder_detection(ds ,sample, layers=layers,epo=epochs,\n",
    "                                              activation_function=activation_function,\n",
    "                                              batch=batch_size,cont=con)\n",
    "\n",
    "        finish=time.time()\n",
    "        print('The outlier detection with '+ method+' is completed.\\n')\n",
    "        print('It took ', finish-start,' seconds')\n",
    "    elif method=='IF':\n",
    "        print('Isolation Forest method initiated for outlier detection')\n",
    "        start=time.time()\n",
    "        ds_pred=my_func.IsolationForest_detection(ds, sample, estimators=estimators)\n",
    "        finish=time.time()\n",
    "        print('The outlier detection with '+ method+' is completed.\\n')\n",
    "        print('It took ', finish-start,' seconds')\n",
    "    elif method=='loda':\n",
    "        print('Lightweight online detection of anomalies initiated for outlier detection')\n",
    "\n",
    "        start=time.time()\n",
    "        ds_pred=my_func.loda_detection(ds, sample)\n",
    "        finish=time.time()\n",
    "        print('The outlier detection with '+ method+' is completed.\\n')\n",
    "        print('It took ', finish-start,' seconds')\n",
    "    elif method=='ngram' and att_ranking==0 :\n",
    "        n, th=input('The number of grams needs to be given as well as the threshold for outlying values\\n'\n",
    "                   'Enter the parameters in the following format (n, th)\\n'\n",
    "                   'e.g. n=2, bigrams will be collected from the values\\n'\n",
    "                   'The threshold determines the acceptable deviance from the average of the frequencies of ngrams\\n'\n",
    "                   'Enter the parameters:').split(',')\n",
    "        n=int(n)\n",
    "        th=float(th)\n",
    "        print(n,'-grams method is initiated for outlier detection')\n",
    "        start=time.time()\n",
    "        ds_pred=my_func.ngrams_detection(ds, n, th)\n",
    "        finish=time.time()\n",
    "        print('The outlier detection with '+ method+' is completed.\\n')\n",
    "        print('It took ', finish-start,' seconds')\n",
    "\n",
    "    \n",
    "\n",
    "    # chunk 6\n",
    "    if att_ranking==0:\n",
    "        # ranking the tuples\n",
    "        if method!='ngram':\n",
    "            ind,th=input('Enter the indicator of the ranking method and the threshold of the most anomalous tuples \\n'\n",
    "                    'in the following format: (ind,th).\\n'\n",
    "                    'Indicator can be 0 or 1,\\n 0: Count of anmolies \\n 1: PageRank Algorithm\\n'\n",
    "                    'The threshold variable determines which tuples index will be returned.\\n'\n",
    "                    'e.g. threshold=0.1, returns the tuples with the top 10% score \\n'\n",
    "                    'Enter the variables:').split(',')\n",
    "            ind=int(ind)\n",
    "            th=float(th)\n",
    "            if ind==0:\n",
    "                final=my_func.count_anomalies(ds_pred,method)\n",
    "                range_of_val=max(final['Ranking_count'])-min(final['Ranking_count'])\n",
    "                limit=(1-th)*range_of_val+min(final['Ranking_count'])\n",
    "                print('The anomalous tuples that exceed the threshold of',1-th,'are:')\n",
    "                print(final[final['Ranking_count']>limit].index)\n",
    "            elif ind==1:\n",
    "                edges=my_func.get_edges(ds_pred,method)\n",
    "                nodes=my_func.get_nodes(ds_pred,method)\n",
    "                G=my_func.build_network(nodes,edges)\n",
    "                final=my_func.pagerank_score(G,ds_pred)\n",
    "                range_of_val=max(final['PageRank score'])-min(final['PageRank score'])\n",
    "                limit=(1-th)*range_of_val+min(final['PageRank score'])\n",
    "                print('The ',th*100,'% most anomalous tuples are:')\n",
    "                print(final[final['PageRank score']>limit].index)\n",
    "        else:\n",
    "            threshold=float(input('The threshold of most anomlaous value must be given\\n'\n",
    "                           'The threshold must belong in [0,1]\\n'\n",
    "                            'e.g. threshold=1 -> returns the whole dataset\\n'\n",
    "                           'Enter the threshold:'))\n",
    "\n",
    "            print(my_func.ngrams_ranking(ds_pred, threshold))\n",
    "    else:\n",
    "        func=input(\"Select a function to calculate the score of the dataframe\\n\"\n",
    "                      'Available functions are: mean, median\\n'\n",
    "                      'Enter the function:').lower()\n",
    "        if method!='ngram':\n",
    "            print(my_func.dataframe_score(ds_pred,ds,method,func))\n",
    "        if method=='ngram':\n",
    "            n, th=input('The number of grams needs to be given as well as the threshold for outlying values\\n'\n",
    "                   'Enter the parameters in the following format (n, th)\\n'\n",
    "                   'e.g. n=2, bigrams will be collected from the values\\n'\n",
    "                   'The threshold determines the acceptable deviance from the average of the frequencies of ngrams\\n'\n",
    "                   'Enter the parameters:').split(',')\n",
    "            n=int(n)\n",
    "            th=float(th)\n",
    "            score=my_func.ngram_score_att(ds,n,th)\n",
    "            norm=my_func.maximum_score_att(ds,n)\n",
    "            if func=='mean':\n",
    "                print (np.mean(score/norm))\n",
    "            if func=='median':\n",
    "                print (np.median(score/norm))\n",
    "            \n",
    "    restart=input('Do you want to restart? (y/n)').lower()\n",
    "    if restart=='y':\n",
    "        main()\n",
    "    else:\n",
    "        exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34168bbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import the path of the file to be tested on anomalies\n",
      "\"C:\\Users\\milia\\thesis\\2016q2t1.xlsx\"\n",
      "Is the dataset extensive or small?\n",
      "Indication: <10000 is small, otherwise it is bigEnter size (small/big):small\n",
      "Do you want to rank the dataset by rows or by attribute?\n",
      "0: Ranking by rows\n",
      "1: Ranking by attributes\n",
      "Enter the variable:\n",
      "\n",
      "0\n",
      "Enter the desired method. \n",
      "available methods are: 'ngram', 'AE', 'IF', 'loda'\n",
      "Enter the parameter:ngram\n",
      "The number of grams needs to be given as well as the threshold for outlying values\n",
      "Enter the parameters in the following format (n, th)\n",
      "e.g. n=2, bigrams will be collected from the values\n",
      "The threshold determines the acceptable deviance from the average of the frequencies of ngrams\n",
      "Enter the parameters:3,0.4\n",
      "3 -grams method is initiated for outlier detection\n",
      "The outlier detection with ngram is completed.\n",
      "\n",
      "It took  0.02620387077331543  seconds\n",
      "The threshold of most anomlaous value must be given\n",
      "The threshold must belong in [0,1]\n",
      "e.g. threshold=1 -> returns the whole dataset\n",
      "Enter the threshold:0.2\n",
      "Int64Index([0, 19, 18, 17], dtype='int64')\n",
      "Do you want to restart? (y/n)n\n"
     ]
    }
   ],
   "source": [
    "main()\n",
    "# \"C:\\Users\\milia\\thesis\\2016q2t1.xlsx\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
